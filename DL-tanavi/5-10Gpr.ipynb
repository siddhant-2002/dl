{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "778db25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, BatchNormalization, Layer, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b4a726e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x272e80f01f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "\n",
    "x_train = resize(x_train, (32, 32))\n",
    "x_test = resize(x_test, (32, 32))\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae3a2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c569a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7534f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_classifier = Sequential()\n",
    "custom_classifier.add(Flatten())\n",
    "custom_classifier.add(Dense(128, activation=\"relu\"))\n",
    "custom_classifier.add(Dropout(0.4))\n",
    "custom_classifier.add(Dense(64, activation='relu'))\n",
    "custom_classifier.add(Dropout(0.4))\n",
    "custom_classifier.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21589268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([vgg_model, custom_classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3c0d60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 10)                74570     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,789,258\n",
      "Trainable params: 74,570\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84743177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=sparse_categorical_crossentropy ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05c3209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 10s 39ms/step - loss: 1.0538 - accuracy: 0.6427 - val_loss: 0.3401 - val_accuracy: 0.8965\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 9s 38ms/step - loss: 0.4135 - accuracy: 0.8745 - val_loss: 0.1870 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 9s 38ms/step - loss: 0.2981 - accuracy: 0.9105 - val_loss: 0.1435 - val_accuracy: 0.9541\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 9s 38ms/step - loss: 0.2443 - accuracy: 0.9280 - val_loss: 0.1298 - val_accuracy: 0.9574\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.2179 - accuracy: 0.9357 - val_loss: 0.1158 - val_accuracy: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272eeb3c310>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=256, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d83a8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg_model.layers[:-4]:\n",
    " layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9d085e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 26s 97ms/step - loss: 1.9321 - accuracy: 0.4023 - val_loss: 0.3168 - val_accuracy: 0.9118\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1795 - accuracy: 0.9566 - val_loss: 0.0614 - val_accuracy: 0.9842\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.0908 - accuracy: 0.9793 - val_loss: 0.0485 - val_accuracy: 0.9866\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.0640 - accuracy: 0.9856 - val_loss: 0.0390 - val_accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.0564 - accuracy: 0.9873 - val_loss: 0.0472 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272f5727f40>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=sparse_categorical_crossentropy ,metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=256, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51cc92",
   "metadata": {},
   "source": [
    "Here we can see using weights of VGG16 model we are able to train a model with high accuracy only in few epochs whereas we are using 20 to 30 epochs in mnist data classification here we are using only 5 epochs also after fine tuning the model by unfreezing the lower 4 layers we can increase the accuracy of model from 96% to 99% in 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10099a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
